batch_size: 1000
memory_size: 100000
batch_per_learn: 20
lr_policy: [0.0005, 0.0005, 0.0005] #attention à bien mettre le même nombre de lr que d'agents
lr_q: [0.1, 0.1, 0.1] #attention à bien mettre le même nombre de lr que d'agents
rho: 0.01
discount: 0.95  # gamma
layer: [10, 10]
start_events: 100000
explo: 0.1